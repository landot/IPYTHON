{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3, due May 2 at 11:59am (i.e., noon).\n",
    "\n",
    "### Before You Start\n",
    "\n",
    "Make sure the following libraries load correctly (hit Ctrl-Enter). Note that while you are loading several powerful libraries, including machine learning libraries, the goal of this problem set is to implement several algorithms from scratch. In particular, you should *not* be using any built-in libraries for nearest neighbors, distance metrics, or cross-validation -- your mission is to write those algorithms in Python! Part 1 will be relatively easy; Part 2 will take more time.\n",
    "\n",
    "*Also note:* For this assignment we are requiring you to use base **matplotlib** - not Seaborn or other packages. This will help you become familiar with techniques for maintaining fine-grained control over your data visualizations. It will also help our graders, who spent countless hours trying to make various versions import for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction to the assignment\n",
    "\n",
    "For this assignment, you will be using the [Boston Housing Prices Data Set](http://archive.ics.uci.edu/ml/datasets/Housing).  Please read about the dataset carefully before continuing.  Use the following commands to load the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "bdata = load_boston()\n",
    "df = pd.DataFrame(bdata.data, columns = bdata.feature_names)\n",
    "newdf = pd.DataFrame(bdata.target)\n",
    "df = pd.concat([df, newdf], axis=1)\n",
    "df.columns.values[13] = 'MEDV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0  </th>\n",
       "      <td>  0.00632</td>\n",
       "      <td> 18.0</td>\n",
       "      <td>  2.31</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 6.575</td>\n",
       "      <td>  65.2</td>\n",
       "      <td> 4.0900</td>\n",
       "      <td>  1</td>\n",
       "      <td> 296</td>\n",
       "      <td> 15.3</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  4.98</td>\n",
       "      <td> 24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1  </th>\n",
       "      <td>  0.02731</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  7.07</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.469</td>\n",
       "      <td> 6.421</td>\n",
       "      <td>  78.9</td>\n",
       "      <td> 4.9671</td>\n",
       "      <td>  2</td>\n",
       "      <td> 242</td>\n",
       "      <td> 17.8</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  9.14</td>\n",
       "      <td> 21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2  </th>\n",
       "      <td>  0.02729</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  7.07</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.469</td>\n",
       "      <td> 7.185</td>\n",
       "      <td>  61.1</td>\n",
       "      <td> 4.9671</td>\n",
       "      <td>  2</td>\n",
       "      <td> 242</td>\n",
       "      <td> 17.8</td>\n",
       "      <td> 392.83</td>\n",
       "      <td>  4.03</td>\n",
       "      <td> 34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3  </th>\n",
       "      <td>  0.03237</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  2.18</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.458</td>\n",
       "      <td> 6.998</td>\n",
       "      <td>  45.8</td>\n",
       "      <td> 6.0622</td>\n",
       "      <td>  3</td>\n",
       "      <td> 222</td>\n",
       "      <td> 18.7</td>\n",
       "      <td> 394.63</td>\n",
       "      <td>  2.94</td>\n",
       "      <td> 33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4  </th>\n",
       "      <td>  0.06905</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  2.18</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.458</td>\n",
       "      <td> 7.147</td>\n",
       "      <td>  54.2</td>\n",
       "      <td> 6.0622</td>\n",
       "      <td>  3</td>\n",
       "      <td> 222</td>\n",
       "      <td> 18.7</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  5.33</td>\n",
       "      <td> 36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5  </th>\n",
       "      <td>  0.02985</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  2.18</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.458</td>\n",
       "      <td> 6.430</td>\n",
       "      <td>  58.7</td>\n",
       "      <td> 6.0622</td>\n",
       "      <td>  3</td>\n",
       "      <td> 222</td>\n",
       "      <td> 18.7</td>\n",
       "      <td> 394.12</td>\n",
       "      <td>  5.21</td>\n",
       "      <td> 28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6  </th>\n",
       "      <td>  0.08829</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 6.012</td>\n",
       "      <td>  66.6</td>\n",
       "      <td> 5.5605</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 395.60</td>\n",
       "      <td> 12.43</td>\n",
       "      <td> 22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7  </th>\n",
       "      <td>  0.14455</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 6.172</td>\n",
       "      <td>  96.1</td>\n",
       "      <td> 5.9505</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 19.15</td>\n",
       "      <td> 27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8  </th>\n",
       "      <td>  0.21124</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 5.631</td>\n",
       "      <td> 100.0</td>\n",
       "      <td> 6.0821</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 386.63</td>\n",
       "      <td> 29.93</td>\n",
       "      <td> 16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9  </th>\n",
       "      <td>  0.17004</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 6.004</td>\n",
       "      <td>  85.9</td>\n",
       "      <td> 6.5921</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 386.71</td>\n",
       "      <td> 17.10</td>\n",
       "      <td> 18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 </th>\n",
       "      <td>  0.22489</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 6.377</td>\n",
       "      <td>  94.3</td>\n",
       "      <td> 6.3467</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 392.52</td>\n",
       "      <td> 20.45</td>\n",
       "      <td> 15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11 </th>\n",
       "      <td>  0.11747</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 6.009</td>\n",
       "      <td>  82.9</td>\n",
       "      <td> 6.2267</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 13.27</td>\n",
       "      <td> 18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 </th>\n",
       "      <td>  0.09378</td>\n",
       "      <td> 12.5</td>\n",
       "      <td>  7.87</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.524</td>\n",
       "      <td> 5.889</td>\n",
       "      <td>  39.0</td>\n",
       "      <td> 5.4509</td>\n",
       "      <td>  5</td>\n",
       "      <td> 311</td>\n",
       "      <td> 15.2</td>\n",
       "      <td> 390.50</td>\n",
       "      <td> 15.71</td>\n",
       "      <td> 21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 </th>\n",
       "      <td>  0.62976</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.949</td>\n",
       "      <td>  61.8</td>\n",
       "      <td> 4.7075</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  8.26</td>\n",
       "      <td> 20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14 </th>\n",
       "      <td>  0.63796</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 6.096</td>\n",
       "      <td>  84.5</td>\n",
       "      <td> 4.4619</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 380.02</td>\n",
       "      <td> 10.26</td>\n",
       "      <td> 18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15 </th>\n",
       "      <td>  0.62739</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.834</td>\n",
       "      <td>  56.5</td>\n",
       "      <td> 4.4986</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 395.62</td>\n",
       "      <td>  8.47</td>\n",
       "      <td> 19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16 </th>\n",
       "      <td>  1.05393</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.935</td>\n",
       "      <td>  29.3</td>\n",
       "      <td> 4.4986</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 386.85</td>\n",
       "      <td>  6.58</td>\n",
       "      <td> 23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17 </th>\n",
       "      <td>  0.78420</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.990</td>\n",
       "      <td>  81.7</td>\n",
       "      <td> 4.2579</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 386.75</td>\n",
       "      <td> 14.67</td>\n",
       "      <td> 17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 </th>\n",
       "      <td>  0.80271</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.456</td>\n",
       "      <td>  36.6</td>\n",
       "      <td> 3.7965</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 288.99</td>\n",
       "      <td> 11.69</td>\n",
       "      <td> 20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19 </th>\n",
       "      <td>  0.72580</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.727</td>\n",
       "      <td>  69.5</td>\n",
       "      <td> 3.7965</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 390.95</td>\n",
       "      <td> 11.28</td>\n",
       "      <td> 18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20 </th>\n",
       "      <td>  1.25179</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.570</td>\n",
       "      <td>  98.1</td>\n",
       "      <td> 3.7979</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 376.57</td>\n",
       "      <td> 21.02</td>\n",
       "      <td> 13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21 </th>\n",
       "      <td>  0.85204</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.965</td>\n",
       "      <td>  89.2</td>\n",
       "      <td> 4.0123</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 392.53</td>\n",
       "      <td> 13.83</td>\n",
       "      <td> 19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22 </th>\n",
       "      <td>  1.23247</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 6.142</td>\n",
       "      <td>  91.7</td>\n",
       "      <td> 3.9769</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 18.72</td>\n",
       "      <td> 15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23 </th>\n",
       "      <td>  0.98843</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.813</td>\n",
       "      <td> 100.0</td>\n",
       "      <td> 4.0952</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 394.54</td>\n",
       "      <td> 19.88</td>\n",
       "      <td> 14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24 </th>\n",
       "      <td>  0.75026</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.924</td>\n",
       "      <td>  94.1</td>\n",
       "      <td> 4.3996</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 394.33</td>\n",
       "      <td> 16.30</td>\n",
       "      <td> 15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25 </th>\n",
       "      <td>  0.84054</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.599</td>\n",
       "      <td>  85.7</td>\n",
       "      <td> 4.4546</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 303.42</td>\n",
       "      <td> 16.51</td>\n",
       "      <td> 13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26 </th>\n",
       "      <td>  0.67191</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 5.813</td>\n",
       "      <td>  90.3</td>\n",
       "      <td> 4.6820</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 376.88</td>\n",
       "      <td> 14.81</td>\n",
       "      <td> 16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27 </th>\n",
       "      <td>  0.95577</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 6.047</td>\n",
       "      <td>  88.8</td>\n",
       "      <td> 4.4534</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 306.38</td>\n",
       "      <td> 17.28</td>\n",
       "      <td> 14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28 </th>\n",
       "      <td>  0.77299</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 6.495</td>\n",
       "      <td>  94.4</td>\n",
       "      <td> 4.4547</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 387.94</td>\n",
       "      <td> 12.80</td>\n",
       "      <td> 18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29 </th>\n",
       "      <td>  1.00245</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  8.14</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.538</td>\n",
       "      <td> 6.674</td>\n",
       "      <td>  87.3</td>\n",
       "      <td> 4.2390</td>\n",
       "      <td>  4</td>\n",
       "      <td> 307</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 380.23</td>\n",
       "      <td> 11.98</td>\n",
       "      <td> 21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>  4.87141</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.614</td>\n",
       "      <td> 6.484</td>\n",
       "      <td>  93.6</td>\n",
       "      <td> 2.3053</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 396.21</td>\n",
       "      <td> 18.68</td>\n",
       "      <td> 16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td> 15.02340</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.614</td>\n",
       "      <td> 5.304</td>\n",
       "      <td>  97.3</td>\n",
       "      <td> 2.1007</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 349.48</td>\n",
       "      <td> 24.91</td>\n",
       "      <td> 12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td> 10.23300</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.614</td>\n",
       "      <td> 6.185</td>\n",
       "      <td>  96.7</td>\n",
       "      <td> 2.1705</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 379.70</td>\n",
       "      <td> 18.03</td>\n",
       "      <td> 14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td> 14.33370</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.614</td>\n",
       "      <td> 6.229</td>\n",
       "      <td>  88.0</td>\n",
       "      <td> 1.9512</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 383.32</td>\n",
       "      <td> 13.11</td>\n",
       "      <td> 21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>  5.82401</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.532</td>\n",
       "      <td> 6.242</td>\n",
       "      <td>  64.7</td>\n",
       "      <td> 3.4242</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 10.74</td>\n",
       "      <td> 23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>  5.70818</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.532</td>\n",
       "      <td> 6.750</td>\n",
       "      <td>  74.9</td>\n",
       "      <td> 3.3317</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 393.07</td>\n",
       "      <td>  7.74</td>\n",
       "      <td> 23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>  5.73116</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.532</td>\n",
       "      <td> 7.061</td>\n",
       "      <td>  77.0</td>\n",
       "      <td> 3.4106</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 395.28</td>\n",
       "      <td>  7.01</td>\n",
       "      <td> 25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>  2.81838</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.532</td>\n",
       "      <td> 5.762</td>\n",
       "      <td>  40.3</td>\n",
       "      <td> 4.0983</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 392.92</td>\n",
       "      <td> 10.42</td>\n",
       "      <td> 21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>  2.37857</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.583</td>\n",
       "      <td> 5.871</td>\n",
       "      <td>  41.9</td>\n",
       "      <td> 3.7240</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 370.73</td>\n",
       "      <td> 13.34</td>\n",
       "      <td> 20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>  3.67367</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.583</td>\n",
       "      <td> 6.312</td>\n",
       "      <td>  51.9</td>\n",
       "      <td> 3.9917</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 388.62</td>\n",
       "      <td> 10.58</td>\n",
       "      <td> 21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>  5.69175</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.583</td>\n",
       "      <td> 6.114</td>\n",
       "      <td>  79.8</td>\n",
       "      <td> 3.5459</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 392.68</td>\n",
       "      <td> 14.98</td>\n",
       "      <td> 19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>  4.83567</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 18.10</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.583</td>\n",
       "      <td> 5.905</td>\n",
       "      <td>  53.2</td>\n",
       "      <td> 3.1523</td>\n",
       "      <td> 24</td>\n",
       "      <td> 666</td>\n",
       "      <td> 20.2</td>\n",
       "      <td> 388.22</td>\n",
       "      <td> 11.45</td>\n",
       "      <td> 20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>  0.15086</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 27.74</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.609</td>\n",
       "      <td> 5.454</td>\n",
       "      <td>  92.7</td>\n",
       "      <td> 1.8209</td>\n",
       "      <td>  4</td>\n",
       "      <td> 711</td>\n",
       "      <td> 20.1</td>\n",
       "      <td> 395.09</td>\n",
       "      <td> 18.06</td>\n",
       "      <td> 15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>  0.18337</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 27.74</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.609</td>\n",
       "      <td> 5.414</td>\n",
       "      <td>  98.3</td>\n",
       "      <td> 1.7554</td>\n",
       "      <td>  4</td>\n",
       "      <td> 711</td>\n",
       "      <td> 20.1</td>\n",
       "      <td> 344.05</td>\n",
       "      <td> 23.97</td>\n",
       "      <td>  7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>  0.20746</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 27.74</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.609</td>\n",
       "      <td> 5.093</td>\n",
       "      <td>  98.0</td>\n",
       "      <td> 1.8226</td>\n",
       "      <td>  4</td>\n",
       "      <td> 711</td>\n",
       "      <td> 20.1</td>\n",
       "      <td> 318.43</td>\n",
       "      <td> 29.68</td>\n",
       "      <td>  8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>  0.10574</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 27.74</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.609</td>\n",
       "      <td> 5.983</td>\n",
       "      <td>  98.8</td>\n",
       "      <td> 1.8681</td>\n",
       "      <td>  4</td>\n",
       "      <td> 711</td>\n",
       "      <td> 20.1</td>\n",
       "      <td> 390.11</td>\n",
       "      <td> 18.07</td>\n",
       "      <td> 13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>  0.11132</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 27.74</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.609</td>\n",
       "      <td> 5.983</td>\n",
       "      <td>  83.5</td>\n",
       "      <td> 2.1099</td>\n",
       "      <td>  4</td>\n",
       "      <td> 711</td>\n",
       "      <td> 20.1</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 13.35</td>\n",
       "      <td> 20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>  0.17331</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 5.707</td>\n",
       "      <td>  54.0</td>\n",
       "      <td> 2.3817</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 12.01</td>\n",
       "      <td> 21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>  0.27957</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 5.926</td>\n",
       "      <td>  42.6</td>\n",
       "      <td> 2.3817</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 13.59</td>\n",
       "      <td> 24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>  0.17899</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 5.670</td>\n",
       "      <td>  28.8</td>\n",
       "      <td> 2.7986</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 393.29</td>\n",
       "      <td> 17.60</td>\n",
       "      <td> 23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>  0.28960</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 5.390</td>\n",
       "      <td>  72.9</td>\n",
       "      <td> 2.7986</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 21.14</td>\n",
       "      <td> 19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>  0.26838</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 5.794</td>\n",
       "      <td>  70.6</td>\n",
       "      <td> 2.8927</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 14.10</td>\n",
       "      <td> 18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>  0.23912</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 6.019</td>\n",
       "      <td>  65.3</td>\n",
       "      <td> 2.4091</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 12.92</td>\n",
       "      <td> 21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>  0.17783</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 5.569</td>\n",
       "      <td>  73.5</td>\n",
       "      <td> 2.3999</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 395.77</td>\n",
       "      <td> 15.10</td>\n",
       "      <td> 17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>  0.22438</td>\n",
       "      <td>  0.0</td>\n",
       "      <td>  9.69</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.585</td>\n",
       "      <td> 6.027</td>\n",
       "      <td>  79.7</td>\n",
       "      <td> 2.4982</td>\n",
       "      <td>  6</td>\n",
       "      <td> 391</td>\n",
       "      <td> 19.2</td>\n",
       "      <td> 396.90</td>\n",
       "      <td> 14.33</td>\n",
       "      <td> 16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>  0.06263</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 11.93</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.573</td>\n",
       "      <td> 6.593</td>\n",
       "      <td>  69.1</td>\n",
       "      <td> 2.4786</td>\n",
       "      <td>  1</td>\n",
       "      <td> 273</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 391.99</td>\n",
       "      <td>  9.67</td>\n",
       "      <td> 22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>  0.04527</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 11.93</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.573</td>\n",
       "      <td> 6.120</td>\n",
       "      <td>  76.7</td>\n",
       "      <td> 2.2875</td>\n",
       "      <td>  1</td>\n",
       "      <td> 273</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  9.08</td>\n",
       "      <td> 20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>  0.06076</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 11.93</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.573</td>\n",
       "      <td> 6.976</td>\n",
       "      <td>  91.0</td>\n",
       "      <td> 2.1675</td>\n",
       "      <td>  1</td>\n",
       "      <td> 273</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  5.64</td>\n",
       "      <td> 23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>  0.10959</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 11.93</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.573</td>\n",
       "      <td> 6.794</td>\n",
       "      <td>  89.3</td>\n",
       "      <td> 2.3889</td>\n",
       "      <td>  1</td>\n",
       "      <td> 273</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 393.45</td>\n",
       "      <td>  6.48</td>\n",
       "      <td> 22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>  0.04741</td>\n",
       "      <td>  0.0</td>\n",
       "      <td> 11.93</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0.573</td>\n",
       "      <td> 6.030</td>\n",
       "      <td>  80.8</td>\n",
       "      <td> 2.5050</td>\n",
       "      <td>  1</td>\n",
       "      <td> 273</td>\n",
       "      <td> 21.0</td>\n",
       "      <td> 396.90</td>\n",
       "      <td>  7.88</td>\n",
       "      <td> 11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD  TAX  \\\n",
       "0     0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296   \n",
       "1     0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242   \n",
       "2     0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
       "3     0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222   \n",
       "4     0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222   \n",
       "5     0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
       "6     0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311   \n",
       "7     0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
       "8     0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
       "9     0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
       "10    0.22489  12.5   7.87     0  0.524  6.377   94.3  6.3467    5  311   \n",
       "11    0.11747  12.5   7.87     0  0.524  6.009   82.9  6.2267    5  311   \n",
       "12    0.09378  12.5   7.87     0  0.524  5.889   39.0  5.4509    5  311   \n",
       "13    0.62976   0.0   8.14     0  0.538  5.949   61.8  4.7075    4  307   \n",
       "14    0.63796   0.0   8.14     0  0.538  6.096   84.5  4.4619    4  307   \n",
       "15    0.62739   0.0   8.14     0  0.538  5.834   56.5  4.4986    4  307   \n",
       "16    1.05393   0.0   8.14     0  0.538  5.935   29.3  4.4986    4  307   \n",
       "17    0.78420   0.0   8.14     0  0.538  5.990   81.7  4.2579    4  307   \n",
       "18    0.80271   0.0   8.14     0  0.538  5.456   36.6  3.7965    4  307   \n",
       "19    0.72580   0.0   8.14     0  0.538  5.727   69.5  3.7965    4  307   \n",
       "20    1.25179   0.0   8.14     0  0.538  5.570   98.1  3.7979    4  307   \n",
       "21    0.85204   0.0   8.14     0  0.538  5.965   89.2  4.0123    4  307   \n",
       "22    1.23247   0.0   8.14     0  0.538  6.142   91.7  3.9769    4  307   \n",
       "23    0.98843   0.0   8.14     0  0.538  5.813  100.0  4.0952    4  307   \n",
       "24    0.75026   0.0   8.14     0  0.538  5.924   94.1  4.3996    4  307   \n",
       "25    0.84054   0.0   8.14     0  0.538  5.599   85.7  4.4546    4  307   \n",
       "26    0.67191   0.0   8.14     0  0.538  5.813   90.3  4.6820    4  307   \n",
       "27    0.95577   0.0   8.14     0  0.538  6.047   88.8  4.4534    4  307   \n",
       "28    0.77299   0.0   8.14     0  0.538  6.495   94.4  4.4547    4  307   \n",
       "29    1.00245   0.0   8.14     0  0.538  6.674   87.3  4.2390    4  307   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...  ...  ...   \n",
       "476   4.87141   0.0  18.10     0  0.614  6.484   93.6  2.3053   24  666   \n",
       "477  15.02340   0.0  18.10     0  0.614  5.304   97.3  2.1007   24  666   \n",
       "478  10.23300   0.0  18.10     0  0.614  6.185   96.7  2.1705   24  666   \n",
       "479  14.33370   0.0  18.10     0  0.614  6.229   88.0  1.9512   24  666   \n",
       "480   5.82401   0.0  18.10     0  0.532  6.242   64.7  3.4242   24  666   \n",
       "481   5.70818   0.0  18.10     0  0.532  6.750   74.9  3.3317   24  666   \n",
       "482   5.73116   0.0  18.10     0  0.532  7.061   77.0  3.4106   24  666   \n",
       "483   2.81838   0.0  18.10     0  0.532  5.762   40.3  4.0983   24  666   \n",
       "484   2.37857   0.0  18.10     0  0.583  5.871   41.9  3.7240   24  666   \n",
       "485   3.67367   0.0  18.10     0  0.583  6.312   51.9  3.9917   24  666   \n",
       "486   5.69175   0.0  18.10     0  0.583  6.114   79.8  3.5459   24  666   \n",
       "487   4.83567   0.0  18.10     0  0.583  5.905   53.2  3.1523   24  666   \n",
       "488   0.15086   0.0  27.74     0  0.609  5.454   92.7  1.8209    4  711   \n",
       "489   0.18337   0.0  27.74     0  0.609  5.414   98.3  1.7554    4  711   \n",
       "490   0.20746   0.0  27.74     0  0.609  5.093   98.0  1.8226    4  711   \n",
       "491   0.10574   0.0  27.74     0  0.609  5.983   98.8  1.8681    4  711   \n",
       "492   0.11132   0.0  27.74     0  0.609  5.983   83.5  2.1099    4  711   \n",
       "493   0.17331   0.0   9.69     0  0.585  5.707   54.0  2.3817    6  391   \n",
       "494   0.27957   0.0   9.69     0  0.585  5.926   42.6  2.3817    6  391   \n",
       "495   0.17899   0.0   9.69     0  0.585  5.670   28.8  2.7986    6  391   \n",
       "496   0.28960   0.0   9.69     0  0.585  5.390   72.9  2.7986    6  391   \n",
       "497   0.26838   0.0   9.69     0  0.585  5.794   70.6  2.8927    6  391   \n",
       "498   0.23912   0.0   9.69     0  0.585  6.019   65.3  2.4091    6  391   \n",
       "499   0.17783   0.0   9.69     0  0.585  5.569   73.5  2.3999    6  391   \n",
       "500   0.22438   0.0   9.69     0  0.585  6.027   79.7  2.4982    6  391   \n",
       "501   0.06263   0.0  11.93     0  0.573  6.593   69.1  2.4786    1  273   \n",
       "502   0.04527   0.0  11.93     0  0.573  6.120   76.7  2.2875    1  273   \n",
       "503   0.06076   0.0  11.93     0  0.573  6.976   91.0  2.1675    1  273   \n",
       "504   0.10959   0.0  11.93     0  0.573  6.794   89.3  2.3889    1  273   \n",
       "505   0.04741   0.0  11.93     0  0.573  6.030   80.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "5       18.7  394.12   5.21  28.7  \n",
       "6       15.2  395.60  12.43  22.9  \n",
       "7       15.2  396.90  19.15  27.1  \n",
       "8       15.2  386.63  29.93  16.5  \n",
       "9       15.2  386.71  17.10  18.9  \n",
       "10      15.2  392.52  20.45  15.0  \n",
       "11      15.2  396.90  13.27  18.9  \n",
       "12      15.2  390.50  15.71  21.7  \n",
       "13      21.0  396.90   8.26  20.4  \n",
       "14      21.0  380.02  10.26  18.2  \n",
       "15      21.0  395.62   8.47  19.9  \n",
       "16      21.0  386.85   6.58  23.1  \n",
       "17      21.0  386.75  14.67  17.5  \n",
       "18      21.0  288.99  11.69  20.2  \n",
       "19      21.0  390.95  11.28  18.2  \n",
       "20      21.0  376.57  21.02  13.6  \n",
       "21      21.0  392.53  13.83  19.6  \n",
       "22      21.0  396.90  18.72  15.2  \n",
       "23      21.0  394.54  19.88  14.5  \n",
       "24      21.0  394.33  16.30  15.6  \n",
       "25      21.0  303.42  16.51  13.9  \n",
       "26      21.0  376.88  14.81  16.6  \n",
       "27      21.0  306.38  17.28  14.8  \n",
       "28      21.0  387.94  12.80  18.4  \n",
       "29      21.0  380.23  11.98  21.0  \n",
       "..       ...     ...    ...   ...  \n",
       "476     20.2  396.21  18.68  16.7  \n",
       "477     20.2  349.48  24.91  12.0  \n",
       "478     20.2  379.70  18.03  14.6  \n",
       "479     20.2  383.32  13.11  21.4  \n",
       "480     20.2  396.90  10.74  23.0  \n",
       "481     20.2  393.07   7.74  23.7  \n",
       "482     20.2  395.28   7.01  25.0  \n",
       "483     20.2  392.92  10.42  21.8  \n",
       "484     20.2  370.73  13.34  20.6  \n",
       "485     20.2  388.62  10.58  21.2  \n",
       "486     20.2  392.68  14.98  19.1  \n",
       "487     20.2  388.22  11.45  20.6  \n",
       "488     20.1  395.09  18.06  15.2  \n",
       "489     20.1  344.05  23.97   7.0  \n",
       "490     20.1  318.43  29.68   8.1  \n",
       "491     20.1  390.11  18.07  13.6  \n",
       "492     20.1  396.90  13.35  20.1  \n",
       "493     19.2  396.90  12.01  21.8  \n",
       "494     19.2  396.90  13.59  24.5  \n",
       "495     19.2  393.29  17.60  23.1  \n",
       "496     19.2  396.90  21.14  19.7  \n",
       "497     19.2  396.90  14.10  18.3  \n",
       "498     19.2  396.90  12.92  21.2  \n",
       "499     19.2  395.77  15.10  17.5  \n",
       "500     19.2  396.90  14.33  16.8  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Experimental Setup\n",
    "\n",
    "The goal of the next few sections is to design an experiment to predict the median home value for an instance in the data.\n",
    "Before beginning the \"real\" work, refamiliarize yourself with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  21.,   55.,   82.,  154.,   84.,   41.,   30.,    8.,   10.,   21.]),\n",
       " array([  5. ,   9.5,  14. ,  18.5,  23. ,  27.5,  32. ,  36.5,  41. ,\n",
       "         45.5,  50. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyoCXpEYZ8JLUqP8PjSc22CVmDj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1871c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare IPython to work with matplotlib and import the library to something convenient\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# edit the code below to make the graph look good\n",
    "plt.hist(bdata.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Scatter plot of housing prices and crime\n",
    "\n",
    "Use matplotlib to create a scatter plot that shows the relationship between the median value of the home (y-axis) and the per-capita crime rate (x-axis).  Properly label your axes, and make sure that your graphic looks polished and professional. No excuses if you don't get it right this time around!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEZCAYAAACXRVJOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x186f19e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creates scatterplot with labels\n",
    "plt.scatter(df.CRIM, df.MEDV)\n",
    "plt.title('Housing Prices vs. Crime')\n",
    "plt.ylabel('Housing Prices in 1000\\'s')\n",
    "plt.xlabel('Per-Capita Crime Rate by Town')\n",
    "\n",
    "#getting rid of spines and ticks\n",
    "#help from divenex http://stackoverflow.com/questions/925024/how-can-i-remove-the-top-and-right-axis-in-matplotlib\n",
    "ax = plt.axes()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Begin by writing a function to compute the Root Mean Squared Error for a list of numbers\n",
    "\n",
    "You can find the sqrt function in the Numpy package. Furthermore the details of RMSE can be found on [Wikipedia](http://en.wikipedia.org/wiki/Root-mean-square_deviation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08166599947\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "compute_rmse\n",
    "\n",
    "Given two arrays, one of actual values and one of predicted values,\n",
    "compute the Roote Mean Squared Error\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "predictions : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "yvalues : array\n",
    "    Array of numerical values corresponding to the actual values for each of the N observations\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : int\n",
    "    Root Mean Squared Error of the prediction\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print compute_rmse((2,2,3),(0,2,6)\n",
    "2.08\n",
    "\"\"\"\n",
    "def compute_rmse(predictions, yvalues):\n",
    "    pred = np.array(predictions)\n",
    "    yval = np.array(yvalues)\n",
    "    rmse = ((pred - yval) ** 2).mean()\n",
    "    rmse = np.sqrt(rmse)\n",
    "    \n",
    "    return rmse\n",
    "    \n",
    "print compute_rmse((2,2,3),(0,2,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Divide your data into training and testing datasets\n",
    "\n",
    "Randomly select 66% of the data and put this in a training dataset (call this \"bdata_train\"), and place the remaining 34% in a testing dataset (call this \"bdata_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-234-a8ee9ad03a9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# enter your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.34\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Tim Landowski\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[1;32m-> 1947\u001b[1;33m                                  (type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "# leave the following line untouched, it will help ensure that your \"random\" split \n",
    "#is the same \"random\" split used by the rest of the class\n",
    "np.random.seed(seed=13579)\n",
    "\n",
    "# enter your code here\n",
    "\n",
    "bdata_train = df.sample(frac=0.1, replace=True)\n",
    "\n",
    "bdata_train, bdata_test = sklearn.cross_validation.train_test_split(df, test_size = 0.34) \n",
    "#bdata_train, bdata_test = train_test_split(df, test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bdata_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bdata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#proof\n",
    "\"%.2f\" % (173.0 / (173.0 + 333.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Use a very bad baseline for prediction, and compute RMSE\n",
    "\n",
    "Create a model that predicts, for every observation x_i, that the median home value is the average (mean) of the median values for all instances in the training set.  Compute the RMSE on the training set.  Now compute the RMSE on the test data set (but use the model you trained on the training set!).  How does RMSE compare for training vs. testing datasets? Is this what you expected, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your code here\n",
    "\n",
    "#get mean from MEDV col in train\n",
    "medVals = []\n",
    "for row in bdata_train:\n",
    "    medVals.append(row[13])\n",
    "med = np.mean(medVals)\n",
    "\n",
    "#print(med)\n",
    "\n",
    "#RMSE for Training Set\n",
    "pred_train = []\n",
    "for i in xrange(len(bdata_train)):\n",
    "    pred_train.append(med)\n",
    "\n",
    "print(compute_rmse(pred_train, medVals))\n",
    "\n",
    "#RMSE for Testing Set\n",
    "pred_test = []\n",
    "for i in xrange(len(bdata_test)):\n",
    "    pred_test.append(med)\n",
    "\n",
    "print(compute_rmse(pred_test, medVals[0:173]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Nearest Neighbors: Distance function\n",
    "Let's try and build a machine learning algorithm to beat the \"Average Value\" baseline that you computed above.  Soon you will implement the Nearest Neighbor algorithm, but first you need to create a distance metric to measure the distance (and similarity) between two instances.  Write a generic function to compute the L-Norm distance (called the [*p*-norm](http://en.wikipedia.org/wiki/Norm_(mathematics) distance on Wikipedia). Verify that your function works by computing the Euclidean distance between the points (3,4) and (6,8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "distance\n",
    "\n",
    "Given two instances and a value for L, return the L-Norm distance between them\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "x1, x2 : array\n",
    "    Array of numerical values corresponding to predictions for each of the N observations\n",
    "\n",
    "L: int\n",
    "    Value of L to use in computing distances\n",
    "\n",
    "Returns\n",
    "-------\n",
    "dist : int\n",
    "    The L-norm distance between instances\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> print distance((3,4),(6,8),2)\n",
    "5\n",
    ">>> print distance((3,4),(6,8),1)\n",
    "7\n",
    "\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "def distance(x1, x2, L):\n",
    "    count = 0\n",
    "    #goes through each index and finds the distance between them (adds to count)\n",
    "    print 'x1 ' , x1\n",
    "    print 'x2 ' , x2\n",
    "    for i in xrange(len(x1)):\n",
    "        difference = np.power(math.fabs(x1[i]-x2[i]), L)\n",
    "        count = count + difference\n",
    "    return np.power(count, 1.0/L)\n",
    "\n",
    "print distance((3,4),(6,8),2)\n",
    "print distance((3,4),(6,8),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Nearest Neighbor algorithm\n",
    "\n",
    "Now things get fun.  Your task is to implement a basic nearest neighbor algorithm from scratch.  Your simple model will use two input features (CRIM and RM) and a single output (MEDV).  In other words, you are modelling the relationship between median home value and crime rates and house size.\n",
    "\n",
    "Use your training data (bdata_train) to \"fit\" your model, although as you know, with Nearest Neighbors there is no real training, you just need to keep your training data in memory.  Write a function that predicts, for each instance in the testing data (bdata_test), the median home value using the nearest neighbor algorithm we discussed in class.  Since this is a small dataset, you can simply compare your test instance to every instance in the training set, and return the MEDV value of the closest training instance.  Have your function take L as an input, where L is passed to the distance function.\n",
    "\n",
    "Compute the RMSE for the Nearest Neighbor predictions on the test set, using the Euclidean distance.  Report an estimate of the total time taken by your code to predict the nearest neighbors for all the values in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "nneighbor\n",
    "\n",
    "Given a training dataset, a testing dataset, and a value for L, return the RMSE\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "bdata_train: \n",
    "    training dataset\n",
    "\n",
    "bdata_test:\n",
    "    testing dataset\n",
    "\n",
    "L: int\n",
    "    Value of L to use in computing distances\n",
    "\n",
    "Returns\n",
    "-------\n",
    "rmse : float\n",
    "    The RMSE for the Nearest Neighbor prediction on the test set\n",
    "\"\"\"\n",
    "import time\n",
    "def nneighbor(bdata_train,bdata_test,input_feat, output, L):\n",
    "    start_time = time.time()\n",
    "    rmse = 0\n",
    "    #goes through each row of test data and calculates distance from each row in train data\n",
    "    pred_arr = []\n",
    "    for i in bdata_test:\n",
    "        dist = 0\n",
    "        for j in bdata_train:\n",
    "            dist = distance(j[0],i[0],L)\n",
    "            print(dist)\n",
    "            pred_arr.append(dist)\n",
    "    rmse = compute_rmse(pred_arr, bdata_test[5])\n",
    "    \n",
    "    print \"Time taken: \" + str(round(time.time() - start_time,2)) + \" seconds\"\n",
    "    return rmse\n",
    "\n",
    "nneighbor(bdata_train, bdata_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Results and Normalization\n",
    "\n",
    "If you were being astute, you would have noticed that we never normalized our features -- a big no-no with Nearest Neighbor algorithms.  Write a generic normalization function that takes as input an array of values for a given feature, and returns the normalized array (subtract the mean and divide by the standard deviation).\n",
    "\n",
    "Re-run the Nearest Neighbor algorithm on the normalized dataset (still just using CRIM and RM as input), and compare the RMSE from this method with your previous RMSE evaluations.\n",
    "\n",
    "*NOTE*: To normalize properly, best practice is to compute the mean and standard deviation on the training set, and use these values to normalize the testing dataset. However, for this problem set, it is okay if you separately normalize each dataset using the respective mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# write your function specification here!\n",
    "\"\"\"\n",
    "def normalize(raw_data):\n",
    "    #your code here\n",
    "    return normalized_data\n",
    "\n",
    "#your additional code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*enter your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Optimization\n",
    "\n",
    "A lot of the decisions we've made so far have been arbitrary.  Try to increase the performance of your nearest neighbor algorithm by adding features that you think might be relevant, and by using different values of L in the distance function.  Try a model that uses a different set of 2 features, then try at least one model that uses more than 4 features, then try using a different value of L.  If you're having fun, try a few different combinations of features and L!\n",
    "\n",
    "What combination of features and distance function provide the lowest RMSE?  Do your decisions affect the running time of the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*enter your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cross-Validation\n",
    "\n",
    "The more you tinkered with your features and distance function, the higher the risk that you overfit your training data.  To prevent this sort of overfitting, you need to use cross-validation (see K-fold [cross-validation](http://en.wikipedia.org/wiki/Cross-validation_(statistics)).  Here you must implement a simple k-fold cross-validation algorithm yourself.  The function you write here will be used several more times in this problem set, so do your best to write efficient code! (Note that the sklearn package has a built-in [K-fold](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) iterator -- you should *not* be invoking that or any related algorithms in this section of the problem set.)\n",
    "\n",
    "Use 10-fold cross-validation and report the average RMSE for Nearest Neighbors using Euclidean distance with CRIM and RM input features, as well as the total running time for the full run of 10 folds.  In other words, randomly divide your dataset into 10 equally-sized samples, and for each of 10 iterations (the \"folds\"), use 9 samples as \"training data\" (even though there is no training in k-NN!), and the remaining 1 sample for testing.  Compute the RMSE of that particular test set, then move on to the next iteration.  Report the average RMSE across the 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 K-Nearest Neighbors Algorithm\n",
    "\n",
    "Implement the K-Nearest Neighbors algorithm.  Using 10-fold cross validation, report the RMSE for K=3 and the running time of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# write your function specification here!\n",
    "\"\"\"\n",
    "def knn(..., L, K):\n",
    "    # enter your code here\n",
    "    return rmse\n",
    "\n",
    "# enter your additional code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Using cross validation to find K\n",
    "\n",
    "What is the best choice of K?  Compute the RMSE for values of K between 1 and 25 using 10-fold cross-validation.  Use the following features in your model, and don't forget to normalize: CRIM, ZN, RM, AGE, DIS, TAX.  Create a graph that shows how RMSE changes as K increases from 1 to 25.  Label your axes, and summarize what you see.  What do you think is a reasonable choice of K for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your observations here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra-Credit: Forward selection\n",
    "\n",
    "Thus far the choice of predictor variables has been rather arbitrary. For extra credit, implement a basic [forward selection](http://www.stat.ubc.ca/~rollin/teach/643w04/lec/node41.html) algorithm to progressively include features that decrease the cross-validated RMSE of the model. Note that the optimal value of K may be different for each model, so you may want to use cross-validation to choose K each time (but it is also fine if you fix K at the optimal value from 2.7).  Create a graph that shows RMSE as a function of the number of features in the model. Label each point on the x-axis with the name of the feature that is added at that step in the forward selection algorithm. *(For instance, if the optimal single-feature model has CRIM with RMSE = 10, and the optimal two-feature model has CRIM+ZN with RMSE=9, the first x-axis label will say CRIM and the second x-axis lable with say ZN)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
